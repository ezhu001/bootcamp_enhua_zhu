{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb250eff-9677-4a60-91da-c6dd9dd10e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHAVANTAGE_API_KEY loaded? True\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "RAW = pathlib.Path('data/raw'); RAW.mkdir(parents=True, exist_ok=True)\n",
    "load_dotenv(); print('ALPHAVANTAGE_API_KEY loaded?', bool(os.getenv('ALPHAVANTAGE_API_KEY')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3204c799-500c-4825-be80-08b74b26a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts():\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def save_csv(df: pd.DataFrame, prefix: str, **meta):\n",
    "    mid = '_'.join([f\"{k}-{v}\" for k,v in meta.items()])\n",
    "    path = RAW / f\"{prefix}_{mid}_{ts()}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print('Saved', path)\n",
    "    return path\n",
    "\n",
    "def validate(df: pd.DataFrame, required):\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    return {'missing': missing, 'shape': df.shape, 'na_total': int(df.isna().sum().sum())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d497a7f0-ab26-4796-839b-a18000f4efc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13466\\AppData\\Local\\Temp\\ipykernel_10728\\2922537616.py:14: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_api = yf.download(SYMBOL, period='12mo', interval='1d').reset_index()[['Date','Close','Open','High','Low','Volume']]\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'missing': [], 'shape': (250, 6), 'na_total': 0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYMBOL = 'AAPL'\n",
    "USE_ALPHA = bool(os.getenv('ALPHAVANTAGE_API_KEY'))\n",
    "try:\n",
    "    url = 'https://www.alphavantage.co/query'\n",
    "    params = {'function':'TIME_SERIES_DAILY_ADJUSTED','symbol':SYMBOL,'outputsize':'compact','apikey':os.getenv('ALPHAVANTAGE_API_KEY')}\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    js = r.json()\n",
    "    key = [k for k in js if 'Time Series' in k][0]\n",
    "    df_api = pd.DataFrame(js[key]).T.reset_index().rename(columns={'index':'date','5. adjusted close':'adj_close'})[['date','adj_close']]\n",
    "    df_api['date'] = pd.to_datetime(df_api['date']); df_api['adj_close'] = pd.to_numeric(df_api['adj_close'])\n",
    "except:\n",
    "    import yfinance as yf\n",
    "    df_api = yf.download(SYMBOL, period='12mo', interval='1d').reset_index()[['Date','Close','Open','High','Low','Volume']]\n",
    "    df_api.columns = ['date','close','open','high','low','volume']\n",
    "\n",
    "v_api = validate(df_api, ['date','close']); v_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5622efba-0f9b-4f22-a93d-2787914470e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存到: data\\api_alpha_AAPL.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "def save_csv(data, prefix, source, symbol):\n",
    "    \"\"\"保存CSV文件并返回完整路径\"\"\"\n",
    "    filename = f\"{prefix}_{source}_{symbol}.csv\"\n",
    "    path = os.path.join('data/raw', filename)\n",
    "    data.to_csv(path, index=False)\n",
    "    return path  # 显式返回路径\n",
    "\n",
    "# 使用示例\n",
    "csv_path = save_csv(\n",
    "    df_api.sort_values('date'), \n",
    "    prefix='api', \n",
    "    source='alpha' if USE_ALPHA else 'yfinance', \n",
    "    symbol=SYMBOL\n",
    ")\n",
    "print(f\"文件已保存到: {csv_path}\")\n",
    "\n",
    "_ = save_csv(df_api.sort_values('date'), prefix='api', source='alpha' if USE_ALPHA else 'yfinance', symbol=SYMBOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "426adbfe-4fb0-405e-ac88-b52c6066f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW -> C:\\Users\\13466\\bootcamp_enhua_zhu\\project\\notebooks\\data\\raw\n",
      "PROC -> C:\\Users\\13466\\bootcamp_enhua_zhu\\project\\notebooks\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "#Directories are created base on the starter\n",
    "#.env created with DATA\\_DIR\\_RAW=data/raw and DATA\\_DIR\\_PROCESSED=data/processed\n",
    "\n",
    "load_dotenv()\n",
    "RAW = pathlib.Path(os.getenv('DATA_DIR_RAW', 'data/raw'))\n",
    "PROC = pathlib.Path(os.getenv('DATA_DIR_PROCESSED', 'data/processed'))\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "print('RAW ->', RAW.resolve())\n",
    "print('PROC ->', PROC.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afb30d23-2ef5-49c0-8f5c-08c2ff8b72ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date       close        open        high         low    volume\n",
      "0  2024-08-19  224.843582  224.674371  224.943125  222.006778  40687800\n",
      "1  2024-08-20  225.460693  224.724131  226.117640  224.405606  30299000\n",
      "2  2024-08-21  225.351212  225.470666  226.923894  224.007474  34765500\n",
      "3  2024-08-22  223.489868  226.734761  227.282216  222.862782  43695300\n",
      "4  2024-08-23  225.789154  224.614628  227.162766  223.290787  38677300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/processed/sample_20250818-213633.parquet')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_csv = pd.read_csv(csv_path)\n",
    "print(df.head())\n",
    "\n",
    "pq_path = PROC / f\"sample_{ts()}.parquet\"\n",
    "try:\n",
    "    df.to_parquet(pq_path)\n",
    "except Exception as e:\n",
    "    print('Parquet engine not available. Install pyarrow or fastparquet to complete this step.')\n",
    "    pq_path = None\n",
    "pq_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dd26965-319a-440b-bd3a-2a4dc9963f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV validation:  {'shape_equal': True, 'date_is_datetime': True, 'close_is_numeric': True}\n",
      "Parquet validation:  {'shape_equal': True, 'date_is_datetime': False, 'close_is_numeric': True}\n"
     ]
    }
   ],
   "source": [
    "def validate_loaded(original, reloaded):\n",
    "    checks = {\n",
    "        'shape_equal': original.shape == reloaded.shape,\n",
    "        'date_is_datetime': pd.api.types.is_datetime64_any_dtype(reloaded['date']) if 'date' in reloaded.columns else False,\n",
    "        'close_is_numeric': pd.api.types.is_numeric_dtype(reloaded['close']) if 'close' in reloaded.columns else False,\n",
    "    }\n",
    "    return checks\n",
    "\n",
    "# Use validate_loaded to check both ways; compare shapes and key dtypes\n",
    "df_csv = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "df_pq = pd.read_parquet(pq_path)\n",
    "try:\n",
    "    print('CSV validation: ',validate_loaded(df, df_csv))\n",
    "except Exception as e:\n",
    "    print('CSV validation fails.', e)\n",
    "try:\n",
    "    print('Parquet validation: ',validate_loaded(df, df_pq))\n",
    "except Exception as e:\n",
    "    print('Parquet validation fails.', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c4b6d61-bc9c-4d2a-8b62-735a7002c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\processed\\util_20250818-213639.parquet\n",
      "         date       close        open        high         low    volume\n",
      "0  2024-08-19  224.843582  224.674371  224.943125  222.006778  40687800\n",
      "1  2024-08-20  225.460693  224.724131  226.117640  224.405606  30299000\n",
      "2  2024-08-21  225.351212  225.470666  226.923894  224.007474  34765500\n",
      "3  2024-08-22  223.489868  226.734761  227.282216  222.862782  43695300\n",
      "4  2024-08-23  225.789154  224.614628  227.162766  223.290787  38677300\n"
     ]
    }
   ],
   "source": [
    "import typing as t, pathlib\n",
    "\n",
    "def detect_format(path: t.Union[str, pathlib.Path]):\n",
    "    s = str(path).lower()\n",
    "    if s.endswith('.csv'): return 'csv'\n",
    "    if s.endswith('.parquet') or s.endswith('.pq') or s.endswith('.parq'): return 'parquet'\n",
    "    raise ValueError('Unsupported format: ' + s)\n",
    "\n",
    "def write_df(df: pd.DataFrame, path: t.Union[str, pathlib.Path]):\n",
    "    p = pathlib.Path(path); p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fmt = detect_format(p)\n",
    "    if fmt == 'csv':\n",
    "        df.to_csv(p, index=False)\n",
    "    else:\n",
    "        try:\n",
    "            df.to_parquet(p)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "    return p\n",
    "\n",
    "def read_df(path: t.Union[str, pathlib.Path]):\n",
    "    p = pathlib.Path(path)\n",
    "    fmt = detect_format(p)\n",
    "    if fmt == 'csv':\n",
    "        return pd.read_csv(p, parse_dates=['date']) if 'date' in pd.read_csv(p, nrows=0).columns else pd.read_csv(p)\n",
    "    else:\n",
    "        try:\n",
    "            return pd.read_parquet(p)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "\n",
    "# \n",
    "p_csv = RAW / f\"util_{ts()}.csv\"\n",
    "p_pq  = PROC / f\"util_{ts()}.parquet\"\n",
    "write_df(df, p_csv); read_df(p_csv).head()\n",
    "try:\n",
    "    print(write_df(df, p_pq)) #data processed\n",
    "    print(read_df(p_pq).head()) #data's header shown\n",
    "except RuntimeError as e:\n",
    "    print('Skipping Parquet util demo:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
